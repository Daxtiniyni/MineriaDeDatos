{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de7abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pyswarm import pso\n",
    "\n",
    "# ----------------- CONFIGURACIÓN -----------------\n",
    "INPUT_CSV     = 'OnlineRetail_Categorias.csv'    # dataset\n",
    "SPMF_TXT      = 'Avance/ItemSetsAvancePreliminar/transactions.txt'  # Archivo que SPMF va a leer\n",
    "HUIM_OUTPUT   = 'Avance/PatronesHUIM/Patrones_HUIM.txt'   # Salida de HUIM\n",
    "SELECTED_OUT  = 'Avance/PatronesPSO/PatronesSelecionados.txt'  # Patrones elegidos por PSO\n",
    "SPMF_JAR_DIR  = '/home/daxtiniyni/tools/spmf'    # ruta al spmf.jar\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_spmf(csv_path, txt_path):\n",
    "\n",
    "    # 2.1 Carga el CSV\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "    \n",
    "    # 2.2 Calcula la utilidad de cada fila: Quantity * UnitPrice\n",
    "    df['Utilidad'] = df['Quantity'] * df['UnitPrice']\n",
    "    \n",
    "    # 2.3 Crea un mapeo de categorías a enteros (Category --> CatID)\n",
    "    únicas = df['Categoria'].unique()\n",
    "    cat2id = {cat: idx+1 for idx, cat in enumerate(únicas)}  # empiezo IDs desde 1\n",
    "    df['CatID'] = df['Categoria'].map(cat2id)\n",
    "    \n",
    "    # 2.4 Agrupa por cada transacción y categoría: suma utilidades de esa categoría en esa factura\n",
    "    grouped = df.groupby(['InvoiceNo', 'CatID'])['Utilidad'].sum().reset_index()\n",
    "    \n",
    "    # 2.5 Ahora agrupo SOLO por transacción (InvoiceNo) para armar cada línea de SPMF\n",
    "    txs = grouped.groupby('InvoiceNo')\n",
    "    \n",
    "    # 2.6 Creo carpeta si no existe\n",
    "    os.makedirs(os.path.dirname(txt_path), exist_ok=True)\n",
    "    \n",
    "    total_utils = []  # para cada factura, guardo la utilidad total\n",
    "    with open(txt_path, 'w') as f:\n",
    "        for invoice, group in txs:\n",
    "            # Para cada categoría dentro de la factura, hacemos (CatID, utilidad_decimal)\n",
    "            items = list(group['CatID'])\n",
    "            # Multiplico por 100 y convierto a entero para evitar decimales en SPMF\n",
    "            utils = list((group['Utilidad'] * 100).astype(int))\n",
    "            # Ordeno por CatID para que SPMF esté feliz\n",
    "            sorted_pairs = sorted(zip(items, utils), key=lambda x: x[0])\n",
    "            \n",
    "            items_sorted = [str(item) for item, _ in sorted_pairs]\n",
    "            utils_sorted = [str(u) for _, u in sorted_pairs]\n",
    "            total_util = sum(int(u) for u in utils_sorted)\n",
    "            total_utils.append(total_util)\n",
    "            \n",
    "            # Formato: \"id1 id2 ... idN : total_util : u1 u2 ... uN\"\n",
    "            linea = \" \".join(items_sorted) + \":\" + str(total_util) + \":\" + \" \".join(utils_sorted) + \"\\n\"\n",
    "            f.write(linea)\n",
    "    \n",
    "    print(f\"[+] BLOQUE 1 completado: CSV → SPMF ({len(txs)} transacciones).\")\n",
    "    return cat2id, total_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9bdc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_huim(input_path, output_path, min_util):\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    jar = os.path.join(SPMF_JAR_DIR, 'spmf.jar')\n",
    "    if not os.path.isfile(jar):\n",
    "        raise FileNotFoundError(f\"spmf.jar no encontrado en {SPMF_JAR_DIR}\")\n",
    "    \n",
    "    cmd = [\n",
    "        'java', '-jar', jar,\n",
    "        'run', 'HUI-Miner',\n",
    "        input_path,\n",
    "        output_path,\n",
    "        str(min_util)\n",
    "    ]\n",
    "    try:\n",
    "        salida = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n",
    "        print(f\"[+] BLOQUE 2 completado: HUIM ejecutado con min_util={min_util}.\\n{salida.decode()}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[!] Error en HUIM:\\n{e.output.decode()}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_patterns(path):\n",
    "    \n",
    "    patterns = []\n",
    "    with open(path, 'r') as f:\n",
    "        for linea in f:\n",
    "            if not linea.strip():\n",
    "                continue\n",
    "            partes = linea.strip().split('#UTIL:')\n",
    "            items = [int(tok) for tok in partes[0].split()]\n",
    "            utilidad = int(partes[1])\n",
    "            patterns.append({'items': items, 'utility': utilidad})\n",
    "    print(f\"[+] BLOQUE 2 completado: Cargados {len(patterns)} patrones HUIM.\")\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591436f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_selected(selected, output_path):\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w') as f:\n",
    "        for p in selected:\n",
    "            linea = \" \".join(map(str, p['items'])) + \"#UTIL:\" + str(p['utility']) + \"\\n\"\n",
    "            f.write(linea)\n",
    "    print(f\"[+] BLOQUE 5 completado: Patrones guardados en {output_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6adc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_mapeo_categorias(csv_path):\n",
    " \n",
    "    df = pd.read_csv(csv_path, dtype=str, encoding='latin1', low_memory=False)\n",
    "    categorias_unicas = sorted(df['Categoria'].unique())\n",
    "    # Asignamos IDs del 1 al N, pero como strings. Ej: 'Almacenamiento': '1'\n",
    "    mapeo = { cat: str(i+1) for i, cat in enumerate(categorias_unicas) }\n",
    "    return mapeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6135e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_transacciones(csv_path, mapeo_cat):\n",
    "\n",
    "    df = pd.read_csv(csv_path, dtype={'InvoiceNo': str}, encoding='latin1', low_memory=False)\n",
    "    transacciones = defaultdict(set)\n",
    "    for _, row in df.iterrows():\n",
    "        cat_texto = row['Categoria']\n",
    "        cat_id = mapeo_cat.get(cat_texto)\n",
    "        # Si por alguna razón falta la categoría en el mapeo, la ignoramos\n",
    "        if cat_id:\n",
    "            transacciones[row['InvoiceNo']].add(cat_id)\n",
    "    return transacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630dc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_patrones_huim(file_path):\n",
    "    patrones = []\n",
    "    with open(file_path, 'r', encoding='latin1') as f:\n",
    "        for linea in f:\n",
    "            linea = linea.strip()\n",
    "            if not linea:\n",
    "                continue\n",
    "            # Quedarse solo con la parte antes de \"#UTIL\"\n",
    "            partes = linea.split('#UTIL')[0].strip()\n",
    "            # Las categorías van separadas por espacio\n",
    "            lista_ids = partes.split()\n",
    "            # Normalizamos como tupla de strings (sin strings vacíos)\n",
    "            pat_tuple = tuple([item for item in lista_ids if item])\n",
    "            if pat_tuple:\n",
    "                patrones.append(pat_tuple)\n",
    "    return patrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50475b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_booleana(patron, transacciones):\n",
    "    cnt = 0\n",
    "    for items in transacciones.values():\n",
    "        # Si cada ID de patron está en el set de items de la transacción\n",
    "        if all(i in items for i in patron):\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_psf(transacciones, patrones_huim, min_freq):\n",
    "    psf = {}\n",
    "    for pat in patrones_huim:\n",
    "        f = freq_booleana(pat, transacciones)\n",
    "        if f >= min_freq:\n",
    "            psf[pat] = f\n",
    "    return psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9366e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11407/3092087419.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] BLOQUE 1 completado: CSV → SPMF (19962 transacciones).\n",
      "[+] Umbral MIN_UTIL calculado: 34855.\n",
      "\n",
      "[+] BLOQUE 2 completado: HUIM ejecutado con min_util=34855.\n",
      ">/home/daxtiniyni/tools/spmf/spmf.jar\n",
      "=============  HUI-MINER ALGORITHM - STATS =============\n",
      " Total time ~ 408 ms\n",
      " Memory ~ 148.09893035888672 MB\n",
      " High-utility itemsets count : 8191\n",
      " Join count : 8178\n",
      "===================================================\n",
      "\n",
      "[+] BLOQUE 3 completado: Cargados 8191 patrones HUIM.\n",
      "\n",
      "¡Proceso completo!\n",
      "Mapa de categorías (Categoría → CatID):\n",
      "  1 → Hogar & DecoraciÃ³n\n",
      "  2 → Otros\n",
      "  3 → Vajilla & CristalerÃ­a\n",
      "  4 → Juguetes & NiÃ±os\n",
      "  5 → Almacenamiento\n",
      "  6 → Bakeware\n",
      "  7 → PapelerÃ­a & Regalos\n",
      "  8 → IluminaciÃ³n\n",
      "  9 → Fiestas & Temporada\n",
      "  10 → Bolsas\n",
      "  11 → Cocina & Utensilios\n",
      "  12 → Textiles & Accesorios\n",
      "  13 → Muebles & Accesorios\n",
      "\n",
      "Mapeo categoría → ID numérico (string):\n",
      "   'Almacenamiento' → '1'\n",
      "   'Bakeware' → '2'\n",
      "   'Bolsas' → '3'\n",
      "   'Cocina & Utensilios' → '4'\n",
      "   'Fiestas & Temporada' → '5'\n",
      "   'Hogar & DecoraciÃ³n' → '6'\n",
      "   'IluminaciÃ³n' → '7'\n",
      "   'Juguetes & NiÃ±os' → '8'\n",
      "   'Muebles & Accesorios' → '9'\n",
      "   'Otros' → '10'\n",
      "   'PapelerÃ­a & Regalos' → '11'\n",
      "   'Textiles & Accesorios' → '12'\n",
      "   'Vajilla & CristalerÃ­a' → '13'\n",
      "\n",
      "⚡ Cargadas 19960 facturas con IDs de categorías.\n",
      "\n",
      "Cargados 8191 patrones HUIM desde 'Avance/PatronesHUIM/Patrones_HUIM.txt'.\n",
      "\n",
      "Patrones Similares Frecuentes (freq >= 3826): 62 encontrados.\n",
      "\n",
      "   10,6,5,1  → 4740 facturas\n",
      "   13,10,6,1  → 4611 facturas\n",
      "   10,6,3,1  → 4254 facturas\n",
      "   10,6,1,2  → 3978 facturas\n",
      "   13,10,6,5  → 3925 facturas\n",
      "   10,6,1  → 7520 facturas\n",
      "   10,6,5  → 6495 facturas\n",
      "   13,10,6  → 6193 facturas\n",
      "   10,5,1  → 5822 facturas\n",
      "   13,10,1  → 5596 facturas\n",
      "   10,3,1  → 5499 facturas\n",
      "   10,6,3  → 5090 facturas\n",
      "   10,6,2  → 5034 facturas\n",
      "   10,1,2  → 4960 facturas\n",
      "   6,5,1  → 4762 facturas\n",
      "   13,6,1  → 4633 facturas\n",
      "   13,10,5  → 4500 facturas\n",
      "   7,10,6  → 4384 facturas\n",
      "   6,3,1  → 4292 facturas\n",
      "   4,10,6  → 4101 facturas\n",
      "   10,3,5  → 4045 facturas\n",
      "   4,10,1  → 4028 facturas\n",
      "   6,1,2  → 3990 facturas\n",
      "   13,6,5  → 3952 facturas\n",
      "   13,10,2  → 3863 facturas\n",
      "   10,5,2  → 3859 facturas\n",
      "   7,10,1  → 3838 facturas\n",
      "   10,6  → 11496 facturas\n",
      "   10,1  → 10551 facturas\n",
      "   10,5  → 8312 facturas\n",
      "   13,10  → 7839 facturas\n",
      "   6,1  → 7610 facturas\n",
      "   10,3  → 6812 facturas\n",
      "   6,5  → 6610 facturas\n",
      "   10,2  → 6606 facturas\n",
      "   13,6  → 6313 facturas\n",
      "   5,1  → 5877 facturas\n",
      "   3,1  → 5696 facturas\n",
      "   13,1  → 5636 facturas\n",
      "   7,10  → 5402 facturas\n",
      "   4,10  → 5277 facturas\n",
      "   6,3  → 5165 facturas\n",
      "   6,2  → 5090 facturas\n",
      "   1,2  → 4985 facturas\n",
      "   13,5  → 4547 facturas\n",
      "   7,6  → 4476 facturas\n",
      "   4,6  → 4130 facturas\n",
      "   3,5  → 4095 facturas\n",
      "   4,1  → 4037 facturas\n",
      "   13,2  → 3913 facturas\n",
      "   5,2  → 3889 facturas\n",
      "   7,1  → 3869 facturas\n",
      "   10  → 18267 facturas\n",
      "   6  → 12086 facturas\n",
      "   1  → 10963 facturas\n",
      "   5  → 8643 facturas\n",
      "   13  → 8153 facturas\n",
      "   3  → 7236 facturas\n",
      "   2  → 6809 facturas\n",
      "   7  → 5641 facturas\n",
      "   4  → 5375 facturas\n",
      "   11  → 3826 facturas\n",
      "\n",
      "  Resultado escrito en 'Avance/PatronesSimilares/psf_desde_huim.txt' (si psf no está vacío).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # BLOQUE 1: Conversiones y HUIM\n",
    "    \n",
    "    # 6.1) Conversiones y percentiles\n",
    "    cat2id, total_utils = convert_csv_to_spmf(INPUT_CSV, SPMF_TXT)\n",
    "    \n",
    "    # 6.2) Definir min_util como el percentil 75 de las utilidades totales\n",
    "    serie = pd.Series(total_utils)\n",
    "    min_util = int(serie.quantile(0.6))\n",
    "    print(f\"[+] Umbral MIN_UTIL calculado: {min_util}.\\n\")\n",
    "    \n",
    "    # 6.3) Ejecutar HUI-Miner de SPMF\n",
    "    run_huim(SPMF_TXT, HUIM_OUTPUT, min_util)\n",
    "    \n",
    "    # 6.4) Parsear patrones HUIM\n",
    "    patterns = parse_patterns(HUIM_OUTPUT)\n",
    "    \n",
    "    # 6.5) Contexto final: mostramos el mapeo de categorías por si lo quieres traducir\n",
    "    print(\"\\n¡Proceso completo!\")\n",
    "    print(\"Mapa de categorías (Categoría → CatID):\")\n",
    "    for cat, idx in cat2id.items():\n",
    "        print(f\"  {idx} → {cat}\")\n",
    "    \n",
    "    \n",
    "    # BLOQUE 2: Mapeo, transacciones y Patrones Similares\n",
    "\n",
    "    CSV_PATH = 'OnlineRetail_Categorias.csv'\n",
    "    HUIM_FILE = 'Avance/PatronesHUIM/Patrones_HUIM.txt'\n",
    "    MIN_FREQ = 3826  # Mínimo de transacciones donde debe aparecer el patrón\n",
    "\n",
    "    # 13.1) Construimos el mapeo categoría→ID\n",
    "    mapeo_cat = construir_mapeo_categorias(CSV_PATH)\n",
    "    print(\"\\nMapeo categoría → ID numérico (string):\")\n",
    "    for cat, idx in mapeo_cat.items():\n",
    "        print(f\"   '{cat}' → '{idx}'\")\n",
    "    print()\n",
    "\n",
    "    # 13.2) Cargo transacciones con IDs en vez de nombres\n",
    "    trans = cargar_transacciones(CSV_PATH, mapeo_cat)\n",
    "    print(f\"⚡ Cargadas {len(trans)} facturas con IDs de categorías.\\n\")\n",
    "\n",
    "    # 13.3) Cargo patterns HUIM (tuplas de strings numéricos)\n",
    "    patrones_huim = cargar_patrones_huim(HUIM_FILE)\n",
    "    print(f\"Cargados {len(patrones_huim)} patrones HUIM desde '{HUIM_FILE}'.\\n\")\n",
    "\n",
    "    # 13.4) Extraigo Patrones Similares Frecuentes\n",
    "    psf = extraer_psf(trans, patrones_huim, MIN_FREQ)\n",
    "\n",
    "    # 13.5) Muestro resultados\n",
    "    print(f\"Patrones Similares Frecuentes (freq >= {MIN_FREQ}): {len(psf)} encontrados.\\n\")\n",
    "    if psf:\n",
    "        # Ordeno por largo de patrón (desc) y luego por frecuencia (desc)\n",
    "        for pat, freq in sorted(psf.items(), key=lambda x: (-len(x[0]), -x[1])):\n",
    "            print(f\"   {','.join(pat)}  → {freq} facturas\")\n",
    "    else:\n",
    "        print(\"(No se encontraron, verifica el MIN_FREQ.)\")\n",
    "\n",
    "    # 13.6) Si quieres guardarlos en un archivo de texto:\n",
    "    output_dir = 'Avance/PatronesSimilares'\n",
    "    os.makedirs(output_dir, exist_ok=True)  # ← Aseguramos que exista la carpeta\n",
    "    output_path = os.path.join(output_dir, 'psf_desde_huim.txt')\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "        for pat, freq in sorted(psf.items(), key=lambda x: (-len(x[0]), -x[1])):\n",
    "            f_out.write(f\"{','.join(pat)} : {freq}\\n\")\n",
    "    print(f\"\\n  Resultado escrito en '{output_path}' (si psf no está vacío).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cfd63e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psf convertido guardado en 'Avance/Resultado/psf_convertido.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1) Ruta de archivos\n",
    "CSV_PATH    = 'OnlineRetail_Categorias.csv'\n",
    "PSF_TXT     = 'Avance/PatronesSimilares/psf_desde_huim.txt'\n",
    "OUTPUT_CSV  = 'Avance/Resultado/psf_convertido.csv'\n",
    "\n",
    "# 2) Reconstruir el mapeo categoría → ID (string) y luego invertirlo a ID → categoría\n",
    "def construir_mapeo_categorias(csv_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str, encoding='latin1', low_memory=False)\n",
    "    categorias_unicas = sorted(df['Categoria'].unique())\n",
    "    # Mapeo categoría → ID (string)\n",
    "    mapeo = {cat: str(i+1) for i, cat in enumerate(categorias_unicas)}\n",
    "    return mapeo\n",
    "\n",
    "mapeo_cat = construir_mapeo_categorias(CSV_PATH)\n",
    "id2cat = {vid: cat for cat, vid in mapeo_cat.items()}\n",
    "\n",
    "# 3) Leer psf_desde_huim.txt y convertir cada línea de IDs a nombres\n",
    "filas = []\n",
    "with open(PSF_TXT, 'r', encoding='utf-8') as f:\n",
    "    for linea in f:\n",
    "        linea = linea.strip()\n",
    "        if not linea:\n",
    "            continue\n",
    "        # Formato esperado: \"id1,id2,... : freq\"\n",
    "        partes = linea.split(':')\n",
    "        ids_str = partes[0].strip()       # \"id1,id2,...\"\n",
    "        freq = int(partes[1].strip())     # frecuencia como entero\n",
    "        lista_ids = [x.strip() for x in ids_str.split(',') if x.strip()]\n",
    "        # Convertir cada ID a nombre de categoría\n",
    "        lista_cats = [id2cat.get(x, f\"ID_{x}_desconocido\") for x in lista_ids]\n",
    "        pattern_nombres = \", \".join(lista_cats)\n",
    "        filas.append({\n",
    "            'Pattern_Categorias': pattern_nombres,\n",
    "            'Frecuencia': freq\n",
    "        })\n",
    "\n",
    "# 4) Crear carpeta de salida si no existe\n",
    "out_dir = os.path.dirname(OUTPUT_CSV)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 5) Generar DataFrame y guardar a CSV\n",
    "df_out = pd.DataFrame(filas, columns=['Pattern_Categorias', 'Frecuencia'])\n",
    "df_out.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"psf convertido guardado en '{OUTPUT_CSV}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "878ed01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 50 patrones en: Avance/Resultado/Patrones_PSO.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar DataFrame de patrones similares frecuentes\n",
    "df = pd.read_csv('Avance/Resultado/psf_convertido.csv')\n",
    "df = df.rename(columns={df.columns[0]: 'pattern', df.columns[1]: 'utility'})\n",
    "\n",
    "# Preparar datos\n",
    "patterns = df['pattern'].astype(str).apply(lambda x: x.split(',')).tolist()\n",
    "U = df['utility'].values\n",
    "\n",
    "# Matriz de similitud (Jaccard)\n",
    "n = len(patterns)\n",
    "S = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    set_i = set(patterns[i])\n",
    "    for j in range(n):\n",
    "        set_j = set(patterns[j])\n",
    "        union = set_i | set_j\n",
    "        S[i, j] = len(set_i & set_j) / len(union) if union else 0\n",
    "np.fill_diagonal(S, 0.0)\n",
    "\n",
    "# Función objetivo\n",
    "def fitness(x, U, S, lambda_param):\n",
    "    util_sum = np.dot(x, U)\n",
    "    redundancy = (x @ S @ x) / 2\n",
    "    return util_sum - lambda_param * redundancy\n",
    "\n",
    "# Parámetros de PSO\n",
    "num_particles = 30\n",
    "num_iterations = 100\n",
    "lambda_param = 0.5\n",
    "w = 0.72\n",
    "c1 = c2 = 1.49\n",
    "\n",
    "# Inicialización\n",
    "dim = n\n",
    "velocities = np.random.uniform(-1, 1, (num_particles, dim))\n",
    "positions = np.random.choice([0, 1], size=(num_particles, dim))\n",
    "\n",
    "pbest_positions = positions.copy()\n",
    "pbest_scores = np.array([fitness(p, U, S, lambda_param) for p in positions])\n",
    "\n",
    "gbest_idx = np.argmax(pbest_scores)\n",
    "gbest_position = pbest_positions[gbest_idx].copy()\n",
    "gbest_score = pbest_scores[gbest_idx]\n",
    "\n",
    "# PSO\n",
    "for it in range(num_iterations):\n",
    "    for i in range(num_particles):\n",
    "        r1, r2 = np.random.rand(dim), np.random.rand(dim)\n",
    "        velocities[i] = (\n",
    "            w * velocities[i]\n",
    "            + c1 * r1 * (pbest_positions[i] - positions[i])\n",
    "            + c2 * r2 * (gbest_position - positions[i])\n",
    "        )\n",
    "        probs = 1.0 / (1.0 + np.exp(-velocities[i]))\n",
    "        positions[i] = (np.random.rand(dim) < probs).astype(int)\n",
    "\n",
    "        score = fitness(positions[i], U, S, lambda_param)\n",
    "        if score > pbest_scores[i]:\n",
    "            pbest_positions[i] = positions[i].copy()\n",
    "            pbest_scores[i] = score\n",
    "            if score > gbest_score:\n",
    "                gbest_position = positions[i].copy()\n",
    "                gbest_score = score\n",
    "\n",
    "# Resultados\n",
    "selected_idxs = np.where(gbest_position == 1)[0]\n",
    "results_df = pd.DataFrame({\n",
    "    'pattern': df['pattern'].iloc[selected_idxs].values,\n",
    "    'utility': df['utility'].iloc[selected_idxs].values\n",
    "})\n",
    "\n",
    "# Crear directorio y guardar resultados\n",
    "output_dir = 'Avance/Resultado'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'Patrones_PSO.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Guardados {len(selected_idxs)} patrones en: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
